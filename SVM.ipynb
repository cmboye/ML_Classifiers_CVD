{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58d75f3d-9ae2-41e3-9b81-81fdedc7412c",
   "metadata": {},
   "source": [
    "# Implement SVM to classify samples as CVD or not \n",
    "## Workflow: \n",
    "1. Read in data\n",
    "1. Prepare SVM\n",
    "     1. Set parameters\n",
    "     2. Train model: Compute gradients and update weights and bias\n",
    "     3. Use model to classify test samples\n",
    "1. Perform kfold cross-validation to assess performance\n",
    "1. Attempt to optimize performance by feature selection and changing parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38eae503-5438-4fe0-8c1d-3327ae85146e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping, found downloaded files in \".\\cardiovascular-disease-dataset\" (use force=True to force download)\n"
     ]
    }
   ],
   "source": [
    "#Import libraries \n",
    "import opendatasets as od \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Read dataset. Note that this requires a Kaggle account\n",
    "od.download(\"https://www.kaggle.com/datasets/sulianova/cardiovascular-disease-dataset\") \n",
    "\n",
    "file=('cardiovascular-disease-dataset/cardio_train.csv') \n",
    "df = pd.read_csv(file,sep=';') \n",
    "  \n",
    "#Preview the data\n",
    "df.head() \n",
    "\n",
    "#Since 'weight' is float, need to change it to int\n",
    "df = df.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81879f6d-f34e-4383-b6bc-f0e14c44297c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVM:\n",
    "    def __init__(self, C=1.0, max_iter=1000, learning_rate=0.01): #Initialize parameters\n",
    "        self.C = C  #Regularization parameter (penalty)\n",
    "        self.max_iter = max_iter #Maximum number of iterations\n",
    "        self.learning_rate = learning_rate #Step size for gradient descent\n",
    "        self.w = None \n",
    "        self.b = None\n",
    "\n",
    "    #Train the SVM model using gradient descent\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        # Initialize weights and bias\n",
    "        self.w = np.zeros(n_features)\n",
    "        self.b = 0\n",
    "        \n",
    "        # Gradient descent\n",
    "        for _ in range(self.max_iter):\n",
    "            for i in range(n_samples):\n",
    "                condition = y[i] * (np.dot(X[i], self.w) + self.b) >= 1 #Decision boundary for the i-th point\n",
    "                if condition: #If classified correctly, the weight remains the same\n",
    "                    dw = self.w  #No regularization if condition met\n",
    "                    db = 0\n",
    "                else: #If point classified incorrectly\n",
    "                    dw = self.w - self.C * y[i] * X[i] #Penalization steps\n",
    "                    db = -self.C * y[i] \n",
    "                \n",
    "                #Update weights and bias\n",
    "                self.w -= self.learning_rate * dw\n",
    "                self.b -= self.learning_rate * db\n",
    "\n",
    "    def classify(self, X):\n",
    "        #Linear decision rule\n",
    "        return np.sign(np.dot(X, self.w) + self.b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58daeefa-e832-4594-a5bd-3725881bd7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#K-fold cross-validation \n",
    "def kfold_crossvalidation(feats,targets,k=3,lr=0.01,penalty=1.0): #feats is features to train the model on, targets is the target variable (CVD), k is number of folds \n",
    "    #Find number of samples\n",
    "    n_samples = feats.shape[0]\n",
    "\n",
    "    #Determine fold size\n",
    "    fold_size= n_samples//k #Use // to return only integer\n",
    "\n",
    "    #List to store the performance scores\n",
    "    performance = []\n",
    "\n",
    "    for i in range(k):\n",
    "        #Define test and train indices\n",
    "        test_start = i * fold_size\n",
    "        test_end = (i + 1) * fold_size if i != k - 1 else n_samples\n",
    "\n",
    "        # Split data into train and test (features and targets)\n",
    "        feats_train = np.concatenate([feats[:test_start], feats[test_end:]], axis=0)\n",
    "        targets_train = np.concatenate([targets[:test_start], targets[test_end:]], axis=0)\n",
    "        feats_test = feats[test_start:test_end]\n",
    "        targets_test = targets[test_start:test_end]\n",
    "\n",
    "        #Train model\n",
    "        model = SVM(learning_rate=lr)\n",
    "        model.fit(feats_train,targets_train)\n",
    "        \n",
    "        #Test model\n",
    "        pred = model.classify(feats_test)\n",
    "\n",
    "        #Calculate performance\n",
    "        def performance_sys(test_true, prediction):\n",
    "            # Count correct predictions\n",
    "            correct_predictions = sum([1 if test_true == prediction else 0 for test_true, prediction in zip(test_true, prediction)])\n",
    "    \n",
    "            # Calculate accuracy\n",
    "            accuracy = correct_predictions / len(test_true)\n",
    "\n",
    "            return accuracy\n",
    "            \n",
    "        #Run performance calculation \n",
    "        performance_score = [] #Init performance score\n",
    "        performance = performance_sys(np.array(targets_test),pred)    \n",
    "        performance_score.append(performance)\n",
    "\n",
    "    #Find average performance\n",
    "    score = np.mean(performance_score)\n",
    "    return score    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c1e26c9-8aa8-43a5-a5fd-a5a0926c9b5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5005714285714286"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Run the above (log regression and cross validation)\n",
    "kfold_crossvalidation(df.drop(columns=['id','cardio'], inplace=False), df.loc[:,'cardio'], k=5) #Set features as all information except id and target, set CVD status as target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed03b57-bebc-4f43-8143-7ed17bed1e68",
   "metadata": {},
   "source": [
    "##### Here we see that not updating any parameters, not utilizing any EDA, and using all features results in a 0.5006 (50.06%) accuracy score. Below, I will try to improve this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f1e4f34-492d-4660-9a82-45a48ad3f31b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "      <th>cholesterol_1</th>\n",
       "      <th>cholesterol_2</th>\n",
       "      <th>cholesterol_3</th>\n",
       "      <th>gluc_1</th>\n",
       "      <th>gluc_2</th>\n",
       "      <th>gluc_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>18393</td>\n",
       "      <td>2</td>\n",
       "      <td>168</td>\n",
       "      <td>62</td>\n",
       "      <td>110</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20228</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>85</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>18857</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>64</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>17623</td>\n",
       "      <td>2</td>\n",
       "      <td>169</td>\n",
       "      <td>82</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>17474</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>56</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    age  gender  height  weight  ap_hi  ap_lo  smoke  alco  active  \\\n",
       "0   0  18393       2     168      62    110     80      0     0       1   \n",
       "1   1  20228       1     156      85    140     90      0     0       1   \n",
       "2   2  18857       1     165      64    130     70      0     0       0   \n",
       "3   3  17623       2     169      82    150    100      0     0       1   \n",
       "4   4  17474       1     156      56    100     60      0     0       0   \n",
       "\n",
       "   cardio  cholesterol_1  cholesterol_2  cholesterol_3  gluc_1  gluc_2  gluc_3  \n",
       "0       0              1              0              0       1       0       0  \n",
       "1       1              0              0              1       1       0       0  \n",
       "2       1              0              0              1       1       0       0  \n",
       "3       1              1              0              0       1       0       0  \n",
       "4       0              1              0              0       1       0       0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.get_dummies(df, columns=['cholesterol', 'gluc'])\n",
    "df1 = df1*1\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "300ce256-a90b-42ec-b7bc-c3fa2f44d767",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5005714285714286"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kfold_crossvalidation(df1.loc[:,['age','cholesterol_1','cholesterol_2','cholesterol_3','weight']], df1.loc[:,'cardio'], k=5) #Removing variables with little predictive power did not increase performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3573de3b-d079-455d-9da5-39eee2fb40a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5005714285714286"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kfold_crossvalidation(df1.loc[:,['age','cholesterol_1','cholesterol_2','cholesterol_3','weight']], df1.loc[:,'cardio'], k=5,lr=0.0001) #Changing learning rate did not affect result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff31a02c-21af-4387-a64f-ef85d2275454",
   "metadata": {},
   "source": [
    "## Future directions:\n",
    "### Adding a function to monitor the gradient descent could aid in troubleshooting and optimizing parameters. Additionally, further EDA (particularly for feature selection) or exploring scaling numerical features might improve performance. Further exploration of the learning rate, as well as testing other similar datasets, could also inform method optimization. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
